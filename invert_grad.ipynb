{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bingguang/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/bingguang/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import socket\n",
    "import datetime\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ResNet152'\n",
    "num_images = 1\n",
    "trained_model = True\n",
    "\n",
    "PIN_MEMORY = True\n",
    "NON_BLOCKING = False\n",
    "BENCHMARK = True\n",
    "MULTITHREAD_DATAPROCESSING = 4\n",
    "\n",
    "\n",
    "cifar10_mean = [0.4914672374725342, 0.4822617471218109, 0.4467701315879822]\n",
    "cifar10_std = [0.24703224003314972, 0.24348513782024384, 0.26158785820007324]\n",
    "cifar100_mean = [0.5071598291397095, 0.4866936206817627, 0.44120192527770996]\n",
    "cifar100_std = [0.2673342823982239, 0.2564384639263153, 0.2761504650115967]\n",
    "mnist_mean = (0.13066373765468597,)\n",
    "mnist_std = (0.30810782313346863,)\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_startup(args=None, defs=None):\n",
    "    \"\"\"Print useful system information.\"\"\"\n",
    "    # Choose GPU device and print status information:\n",
    "    device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    setup = dict(device=device, dtype=torch.float)  # non_blocking=NON_BLOCKING\n",
    "    print('Currently evaluating -------------------------------:')\n",
    "    print(datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\"))\n",
    "    print(f'CPUs: {torch.get_num_threads()}, GPUs: {torch.cuda.device_count()} on {socket.gethostname()}.')\n",
    "    if args is not None:\n",
    "        print(args)\n",
    "    if defs is not None:\n",
    "        print(repr(defs))\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'GPU : {torch.cuda.get_device_name(device=device)}')\n",
    "    return setup\n",
    "\n",
    "def training_strategy(strategy, lr=None, epochs=None, dryrun=False):\n",
    "    \"\"\"Parse training strategy.\"\"\"\n",
    "    if strategy == 'conservative':\n",
    "        defs = ConservativeStrategy(lr, epochs, dryrun)\n",
    "    elif strategy == 'adam':\n",
    "        defs = AdamStrategy(lr, epochs, dryrun)\n",
    "    else:\n",
    "        raise ValueError('Unknown training strategy.')\n",
    "    return defs\n",
    "\n",
    "@dataclass\n",
    "class Strategy:\n",
    "    \"\"\"Default usual parameters, not intended for parsing.\"\"\"\n",
    "\n",
    "    epochs : int\n",
    "    batch_size : int\n",
    "    optimizer : str\n",
    "    lr : float\n",
    "    scheduler : str\n",
    "    weight_decay : float\n",
    "    validate : int\n",
    "    warmup: bool\n",
    "    dryrun : bool\n",
    "    dropout : float\n",
    "    augmentations : bool\n",
    "\n",
    "    def __init__(self, lr=None, epochs=None, dryrun=False):\n",
    "        \"\"\"Defaulted parameters. Apply overwrites from args.\"\"\"\n",
    "        if epochs is not None:\n",
    "            self.epochs = epochs\n",
    "        if lr is not None:\n",
    "            self.lr = lr\n",
    "        if dryrun:\n",
    "            self.dryrun = dryrun\n",
    "        self.validate = 10\n",
    "\n",
    "@dataclass\n",
    "class ConservativeStrategy(Strategy):\n",
    "    \"\"\"Default usual parameters, defines a config object.\"\"\"\n",
    "\n",
    "    def __init__(self, lr=None, epochs=None, dryrun=False):\n",
    "        \"\"\"Initialize training hyperparameters.\"\"\"\n",
    "        self.lr = 0.1\n",
    "        self.epochs = 120\n",
    "        self.batch_size = 128\n",
    "        self.optimizer = 'SGD'\n",
    "        self.scheduler = 'linear'\n",
    "        self.warmup = False\n",
    "        self.weight_decay : float = 5e-4\n",
    "        self.dropout = 0.0\n",
    "        self.augmentations = True\n",
    "        self.dryrun = False\n",
    "        super().__init__(lr=None, epochs=None, dryrun=False)\n",
    "\n",
    "@dataclass\n",
    "class AdamStrategy(Strategy):\n",
    "    \"\"\"Start slowly. Use a tame Adam.\"\"\"\n",
    "\n",
    "    def __init__(self, lr=None, epochs=None, dryrun=False):\n",
    "        \"\"\"Initialize training hyperparameters.\"\"\"\n",
    "        self.lr = 1e-3 / 10\n",
    "        self.epochs = 120\n",
    "        self.batch_size = 32\n",
    "        self.optimizer = 'AdamW'\n",
    "        self.scheduler = 'linear'\n",
    "        self.warmup = True\n",
    "        self.weight_decay : float = 5e-4\n",
    "        self.dropout = 0.0\n",
    "        self.augmentations = True\n",
    "        self.dryrun = False\n",
    "        super().__init__(lr=None, epochs=None, dryrun=False)\n",
    "        \n",
    "def construct_dataloaders(dataset, defs, data_path='~/data', shuffle=True, normalize=True):\n",
    "    \"\"\"Return a dataloader with given dataset and augmentation, normalize data?.\"\"\"\n",
    "    path = os.path.expanduser(data_path)\n",
    "\n",
    "    if dataset == 'CIFAR10':\n",
    "        trainset, validset = _build_cifar10(path, defs.augmentations, normalize)\n",
    "        loss_fn = Classification()\n",
    "    elif dataset == 'CIFAR100':\n",
    "        trainset, validset = _build_cifar100(path, defs.augmentations, normalize)\n",
    "        loss_fn = Classification()\n",
    "    elif dataset == 'MNIST':\n",
    "        trainset, validset = _build_mnist(path, defs.augmentations, normalize)\n",
    "        loss_fn = Classification()\n",
    "    elif dataset == 'MNIST_GRAY':\n",
    "        trainset, validset = _build_mnist_gray(path, defs.augmentations, normalize)\n",
    "        loss_fn = Classification()\n",
    "    elif dataset == 'ImageNet':\n",
    "        trainset, validset = _build_imagenet(path, defs.augmentations, normalize)\n",
    "        loss_fn = Classification()\n",
    "\n",
    "    if MULTITHREAD_DATAPROCESSING:\n",
    "        num_workers = min(torch.get_num_threads(), MULTITHREAD_DATAPROCESSING) if torch.get_num_threads() > 1 else 0\n",
    "    else:\n",
    "        num_workers = 0\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=min(defs.batch_size, len(trainset)),\n",
    "                                            shuffle=shuffle, drop_last=True, num_workers=num_workers, pin_memory=PIN_MEMORY)\n",
    "    validloader = torch.utils.data.DataLoader(validset, batch_size=min(defs.batch_size, len(trainset)),\n",
    "                                            shuffle=False, drop_last=False, num_workers=num_workers, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    return loss_fn, trainloader, validloader\n",
    "\n",
    "def _build_cifar10(data_path, augmentations=True, normalize=True):\n",
    "    \"\"\"Define CIFAR-10 with everything considered.\"\"\"\n",
    "    # Load data\n",
    "    trainset = torchvision.datasets.CIFAR10(root=data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    validset = torchvision.datasets.CIFAR10(root=data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    if cifar10_mean is None:\n",
    "        data_mean, data_std = _get_meanstd(trainset)\n",
    "    else:\n",
    "        data_mean, data_std = cifar10_mean, cifar10_std\n",
    "\n",
    "    # Organize preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std) if normalize else transforms.Lambda(lambda x: x)])\n",
    "    if augmentations:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transform])\n",
    "        trainset.transform = transform_train\n",
    "    else:\n",
    "        trainset.transform = transform\n",
    "    validset.transform = transform\n",
    "\n",
    "    return trainset, validset\n",
    "\n",
    "def _build_cifar100(data_path, augmentations=True, normalize=True):\n",
    "    \"\"\"Define CIFAR-100 with everything considered.\"\"\"\n",
    "    # Load data\n",
    "    trainset = torchvision.datasets.CIFAR100(root=data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    validset = torchvision.datasets.CIFAR100(root=data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    if cifar100_mean is None:\n",
    "        data_mean, data_std = _get_meanstd(trainset)\n",
    "    else:\n",
    "        data_mean, data_std = cifar100_mean, cifar100_std\n",
    "\n",
    "    # Organize preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std) if normalize else transforms.Lambda(lambda x: x)])\n",
    "    if augmentations:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transform])\n",
    "        trainset.transform = transform_train\n",
    "    else:\n",
    "        trainset.transform = transform\n",
    "    validset.transform = transform\n",
    "\n",
    "    return trainset, validset\n",
    "\n",
    "def _build_mnist(data_path, augmentations=True, normalize=True):\n",
    "    \"\"\"Define MNIST with everything considered.\"\"\"\n",
    "    # Load data\n",
    "    trainset = torchvision.datasets.MNIST(root=data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    validset = torchvision.datasets.MNIST(root=data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    if mnist_mean is None:\n",
    "        cc = torch.cat([trainset[i][0].reshape(-1) for i in range(len(trainset))], dim=0)\n",
    "        data_mean = (torch.mean(cc, dim=0).item(),)\n",
    "        data_std = (torch.std(cc, dim=0).item(),)\n",
    "    else:\n",
    "        data_mean, data_std = mnist_mean, mnist_std\n",
    "\n",
    "    # Organize preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std) if normalize else transforms.Lambda(lambda x: x)])\n",
    "    if augmentations:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(28, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transform])\n",
    "        trainset.transform = transform_train\n",
    "    else:\n",
    "        trainset.transform = transform\n",
    "    validset.transform = transform\n",
    "\n",
    "    return trainset, validset\n",
    "\n",
    "def _build_mnist_gray(data_path, augmentations=True, normalize=True):\n",
    "    \"\"\"Define MNIST with everything considered.\"\"\"\n",
    "    # Load data\n",
    "    trainset = torchvision.datasets.MNIST(root=data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    validset = torchvision.datasets.MNIST(root=data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    if mnist_mean is None:\n",
    "        cc = torch.cat([trainset[i][0].reshape(-1) for i in range(len(trainset))], dim=0)\n",
    "        data_mean = (torch.mean(cc, dim=0).item(),)\n",
    "        data_std = (torch.std(cc, dim=0).item(),)\n",
    "    else:\n",
    "        data_mean, data_std = mnist_mean, mnist_std\n",
    "\n",
    "    # Organize preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std) if normalize else transforms.Lambda(lambda x: x)])\n",
    "    if augmentations:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.RandomCrop(28, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transform])\n",
    "        trainset.transform = transform_train\n",
    "    else:\n",
    "        trainset.transform = transform\n",
    "    validset.transform = transform\n",
    "\n",
    "    return trainset, validset\n",
    "\n",
    "def _build_imagenet(data_path, augmentations=True, normalize=True):\n",
    "    \"\"\"Define ImageNet with everything considered.\"\"\"\n",
    "    # Load data\n",
    "    trainset = torchvision.datasets.ImageNet(root=data_path, split='train', transform=transforms.ToTensor())\n",
    "    validset = torchvision.datasets.ImageNet(root=data_path, split='val', transform=transforms.ToTensor())\n",
    "\n",
    "    if imagenet_mean is None:\n",
    "        data_mean, data_std = _get_meanstd(trainset)\n",
    "    else:\n",
    "        data_mean, data_std = imagenet_mean, imagenet_std\n",
    "\n",
    "    # Organize preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std) if normalize else transforms.Lambda(lambda x : x)])\n",
    "    if augmentations:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(data_mean, data_std) if normalize else transforms.Lambda(lambda x : x)])\n",
    "        trainset.transform = transform_train\n",
    "    else:\n",
    "        trainset.transform = transform\n",
    "    validset.transform = transform\n",
    "\n",
    "    return trainset, validset\n",
    "\n",
    "def _get_meanstd(dataset):\n",
    "    cc = torch.cat([trainset[i][0].reshape(3, -1) for i in range(len(trainset))], dim=1)\n",
    "    data_mean = torch.mean(cc, dim=1).tolist()\n",
    "    data_std = torch.std(cc, dim=1).tolist()\n",
    "    return data_mean, data_std\n",
    "\n",
    "class Loss:\n",
    "    \"\"\"Abstract class, containing necessary methods.\n",
    "\n",
    "    Abstract class to collect information about the 'higher-level' loss function, used to train an energy-based model\n",
    "    containing the evaluation of the loss function, its gradients w.r.t. to first and second argument and evaluations\n",
    "    of the actual metric that is targeted.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self, reference, argmin):\n",
    "        \"\"\"Return l(x, y).\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        return value, name, format\n",
    "\n",
    "    def metric(self, reference, argmin):\n",
    "        \"\"\"The actually sought metric.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        return value, name, format\n",
    "\n",
    "class PSNR(Loss):\n",
    "    \"\"\"A classical MSE target.\n",
    "\n",
    "    The minimized criterion is MSE Loss, the actual metric is average PSNR.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init with torch MSE.\"\"\"\n",
    "        self.loss_fn = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "    def __call__(self, x=None, y=None):\n",
    "        \"\"\"Return l(x, y).\"\"\"\n",
    "        name = 'MSE'\n",
    "        format = '.6f'\n",
    "        if x is None:\n",
    "            return name, format\n",
    "        else:\n",
    "            value = 0.5 * self.loss_fn(x, y)\n",
    "            return value, name, format\n",
    "\n",
    "    def metric(self, x=None, y=None):\n",
    "        \"\"\"The actually sought metric.\"\"\"\n",
    "        name = 'avg PSNR'\n",
    "        format = '.3f'\n",
    "        if x is None:\n",
    "            return name, format\n",
    "        else:\n",
    "            value = self.psnr_compute(x, y)\n",
    "            return value, name, format\n",
    "\n",
    "    @staticmethod\n",
    "    def psnr_compute(img_batch, ref_batch, batched=False, factor=1.0):\n",
    "        \"\"\"Standard PSNR.\"\"\"\n",
    "        def get_psnr(img_in, img_ref):\n",
    "            mse = ((img_in - img_ref)**2).mean()\n",
    "            if mse > 0 and torch.isfinite(mse):\n",
    "                return (10 * torch.log10(factor**2 / mse)).item()\n",
    "            elif not torch.isfinite(mse):\n",
    "                return float('nan')\n",
    "            else:\n",
    "                return float('inf')\n",
    "\n",
    "        if batched:\n",
    "            psnr = get_psnr(img_batch.detach(), ref_batch)\n",
    "        else:\n",
    "            [B, C, m, n] = img_batch.shape\n",
    "            psnrs = []\n",
    "            for sample in range(B):\n",
    "                psnrs.append(get_psnr(img_batch.detach()[sample, :, :, :], ref_batch[sample, :, :, :]))\n",
    "            psnr = np.mean(psnrs)\n",
    "\n",
    "        return psnr\n",
    "    \n",
    "class Classification(Loss):\n",
    "    \"\"\"A classical NLL loss for classification. Evaluation has the softmax baked in.\n",
    "\n",
    "    The minimized criterion is cross entropy, the actual metric is total accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init with torch MSE.\"\"\"\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100,\n",
    "                                                reduce=None, reduction='mean')\n",
    "\n",
    "    def __call__(self, x=None, y=None):\n",
    "        \"\"\"Return l(x, y).\"\"\"\n",
    "        name = 'CrossEntropy'\n",
    "        format = '1.5f'\n",
    "        if x is None:\n",
    "            return name, format\n",
    "        else:\n",
    "            value = self.loss_fn(x, y)\n",
    "            return value, name, format\n",
    "\n",
    "    def metric(self, x=None, y=None):\n",
    "        \"\"\"The actually sought metric.\"\"\"\n",
    "        name = 'Accuracy'\n",
    "        format = '6.2%'\n",
    "        if x is None:\n",
    "            return name, format\n",
    "        else:\n",
    "            value = (x.data.argmax(dim=1) == y).sum().float() / y.shape[0]\n",
    "            return value.detach(), name, format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently evaluating -------------------------------:\n",
      "Sunday, 19. January 2025 11:48PM\n",
      "CPUs: 24, GPUs: 1 on stair-Alienware-Aurora-R16.\n",
      "GPU : NVIDIA GeForce RTX 4090\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "setup = system_startup()\n",
    "defs = training_strategy('conservative')\n",
    "loss_fn, trainloader, validloader =  construct_dataloaders('CIFAR10', defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=233):\n",
    "    \"\"\"233 = 144 + 89 is my favorite number.\"\"\"\n",
    "    torch.manual_seed(seed + 1)\n",
    "    torch.cuda.manual_seed(seed + 2)\n",
    "    torch.cuda.manual_seed_all(seed + 3)\n",
    "    np.random.seed(seed + 4)\n",
    "    torch.cuda.manual_seed_all(seed + 5)\n",
    "    random.seed(seed + 6)\n",
    "\n",
    "def construct_model(model, num_classes=10, seed=None, num_channels=3, modelkey=None):\n",
    "    \"\"\"Return various models.\"\"\"\n",
    "    if modelkey is None:\n",
    "        if seed is None:\n",
    "            model_init_seed = np.random.randint(0, 2**32 - 10)\n",
    "        else:\n",
    "            model_init_seed = seed\n",
    "    else:\n",
    "        model_init_seed = modelkey\n",
    "    set_random_seed(model_init_seed)\n",
    "\n",
    "    if model in ['ConvNet', 'ConvNet64']:\n",
    "        model = ConvNet(width=64, num_channels=num_channels, num_classes=num_classes)\n",
    "    elif model == 'ConvNet8':\n",
    "        model = ConvNet(width=64, num_channels=num_channels, num_classes=num_classes)\n",
    "    elif model == 'ConvNet16':\n",
    "        model = ConvNet(width=64, num_channels=num_channels, num_classes=num_classes)\n",
    "    elif model == 'ConvNet32':\n",
    "        model = ConvNet(width=64, num_channels=num_channels, num_classes=num_classes)\n",
    "    elif model == 'BeyondInferringMNIST':\n",
    "        model = torch.nn.Sequential(OrderedDict([\n",
    "            ('conv1', torch.nn.Conv2d(1, 32, 3, stride=2, padding=1)),\n",
    "            ('relu0', torch.nn.LeakyReLU()),\n",
    "            ('conv2', torch.nn.Conv2d(32, 64, 3, stride=1, padding=1)),\n",
    "            ('relu1', torch.nn.LeakyReLU()),\n",
    "            ('conv3', torch.nn.Conv2d(64, 128, 3, stride=2, padding=1)),\n",
    "            ('relu2', torch.nn.LeakyReLU()),\n",
    "            ('conv4', torch.nn.Conv2d(128, 256, 3, stride=1, padding=1)),\n",
    "            ('relu3', torch.nn.LeakyReLU()),\n",
    "            ('flatt', torch.nn.Flatten()),\n",
    "            ('linear0', torch.nn.Linear(12544, 12544)),\n",
    "            ('relu4', torch.nn.LeakyReLU()),\n",
    "            ('linear1', torch.nn.Linear(12544, 10)),\n",
    "            ('softmax', torch.nn.Softmax(dim=1))\n",
    "        ]))\n",
    "    elif model == 'BeyondInferringCifar':\n",
    "        model = torch.nn.Sequential(OrderedDict([\n",
    "            ('conv1', torch.nn.Conv2d(3, 32, 3, stride=2, padding=1)),\n",
    "            ('relu0', torch.nn.LeakyReLU()),\n",
    "            ('conv2', torch.nn.Conv2d(32, 64, 3, stride=1, padding=1)),\n",
    "            ('relu1', torch.nn.LeakyReLU()),\n",
    "            ('conv3', torch.nn.Conv2d(64, 128, 3, stride=2, padding=1)),\n",
    "            ('relu2', torch.nn.LeakyReLU()),\n",
    "            ('conv4', torch.nn.Conv2d(128, 256, 3, stride=1, padding=1)),\n",
    "            ('relu3', torch.nn.LeakyReLU()),\n",
    "            ('flatt', torch.nn.Flatten()),\n",
    "            ('linear0', torch.nn.Linear(12544, 12544)),\n",
    "            ('relu4', torch.nn.LeakyReLU()),\n",
    "            ('linear1', torch.nn.Linear(12544, 10)),\n",
    "            ('softmax', torch.nn.Softmax(dim=1))\n",
    "        ]))\n",
    "    elif model == 'MLP':\n",
    "        width = 1024\n",
    "        model = torch.nn.Sequential(OrderedDict([\n",
    "            ('flatten', torch.nn.Flatten()),\n",
    "            ('linear0', torch.nn.Linear(3072, width)),\n",
    "            ('relu0', torch.nn.ReLU()),\n",
    "            ('linear1', torch.nn.Linear(width, width)),\n",
    "            ('relu1', torch.nn.ReLU()),\n",
    "            ('linear2', torch.nn.Linear(width, width)),\n",
    "            ('relu2', torch.nn.ReLU()),\n",
    "            ('linear3', torch.nn.Linear(width, num_classes))]))\n",
    "    elif model == 'TwoLP':\n",
    "        width = 2048\n",
    "        model = torch.nn.Sequential(OrderedDict([\n",
    "            ('flatten', torch.nn.Flatten()),\n",
    "            ('linear0', torch.nn.Linear(3072, width)),\n",
    "            ('relu0', torch.nn.ReLU()),\n",
    "            ('linear3', torch.nn.Linear(width, num_classes))]))\n",
    "    elif model == 'ResNet20':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [3, 3, 3], num_classes=num_classes, base_width=16)\n",
    "    elif model == 'ResNet20-nostride':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [3, 3, 3], num_classes=num_classes, base_width=16,\n",
    "                    strides=[1, 1, 1, 1])\n",
    "    elif model == 'ResNet20-10':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [3, 3, 3], num_classes=num_classes, base_width=16 * 10)\n",
    "    elif model == 'ResNet20-4':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [3, 3, 3], num_classes=num_classes, base_width=16 * 4)\n",
    "    elif model == 'ResNet20-4-unpooled':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [3, 3, 3], num_classes=num_classes, base_width=16 * 4,\n",
    "                    pool='max')\n",
    "    elif model == 'ResNet28-10':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [4, 4, 4], num_classes=num_classes, base_width=16 * 10)\n",
    "    elif model == 'ResNet32':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [5, 5, 5], num_classes=num_classes, base_width=16)\n",
    "    elif model == 'ResNet32-10':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [5, 5, 5], num_classes=num_classes, base_width=16 * 10)\n",
    "    elif model == 'ResNet44':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [7, 7, 7], num_classes=num_classes, base_width=16)\n",
    "    elif model == 'ResNet56':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [9, 9, 9], num_classes=num_classes, base_width=16)\n",
    "    elif model == 'ResNet110':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [18, 18, 18], num_classes=num_classes, base_width=16)\n",
    "    elif model == 'ResNet18':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=num_classes, base_width=64)\n",
    "    elif model == 'ResNet34':\n",
    "        model = ResNet(torchvision.models.resnet.BasicBlock, [3, 4, 6, 3], num_classes=num_classes, base_width=64)\n",
    "    elif model == 'ResNet50':\n",
    "        model = ResNet(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], num_classes=num_classes, base_width=64)\n",
    "    elif model == 'ResNet50-2':\n",
    "        model = ResNet(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], num_classes=num_classes, base_width=64 * 2)\n",
    "    elif model == 'ResNet101':\n",
    "        model = ResNet(torchvision.models.resnet.Bottleneck, [3, 4, 23, 3], num_classes=num_classes, base_width=64)\n",
    "    elif model == 'ResNet152':\n",
    "        model = ResNet(torchvision.models.resnet.Bottleneck, [3, 8, 36, 3], num_classes=num_classes, base_width=64)\n",
    "    elif model == 'MobileNet':\n",
    "        inverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 1],  # cifar adaptation, cf.https://github.com/kuangliu/pytorch-cifar/blob/master/models/mobilenetv2.py\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        model = torchvision.models.MobileNetV2(num_classes=num_classes,\n",
    "                                               inverted_residual_setting=inverted_residual_setting,\n",
    "                                               width_mult=1.0)\n",
    "        model.features[0] = torchvision.models.mobilenet.ConvBNReLU(num_channels, 32, stride=1)  # this is fixed to width=1\n",
    "    elif model == 'MNASNet':\n",
    "        model = torchvision.models.MNASNet(1.0, num_classes=num_classes, dropout=0.2)\n",
    "    elif model == 'DenseNet121':\n",
    "        model = torchvision.models.DenseNet(growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                                            num_init_features=64, bn_size=4, drop_rate=0, num_classes=num_classes,\n",
    "                                            memory_efficient=False)\n",
    "    elif model == 'DenseNet40':\n",
    "        model = _DenseNet(_Bottleneck, [6, 6, 6, 0], growth_rate=12, num_classes=num_classes)\n",
    "    elif model == 'DenseNet40-4':\n",
    "        model = _DenseNet(_Bottleneck, [6, 6, 6, 0], growth_rate=12 * 4, num_classes=num_classes)\n",
    "    elif model == 'SRNet3':\n",
    "        model = SRNet(upscale_factor=3, num_channels=num_channels)\n",
    "    elif model == 'SRNet1':\n",
    "        model = SRNet(upscale_factor=1, num_channels=num_channels)\n",
    "    elif model == 'iRevNet':\n",
    "        if num_classes <= 100:\n",
    "            in_shape = [num_channels, 32, 32]  # only for cifar right now\n",
    "            model = iRevNet(nBlocks=[18, 18, 18], nStrides=[1, 2, 2],\n",
    "                            nChannels=[16, 64, 256], nClasses=num_classes,\n",
    "                            init_ds=0, dropout_rate=0.1, affineBN=True,\n",
    "                            in_shape=in_shape, mult=4)\n",
    "        else:\n",
    "            in_shape = [3, 224, 224]  # only for imagenet\n",
    "            model = iRevNet(nBlocks=[6, 16, 72, 6], nStrides=[2, 2, 2, 2],\n",
    "                            nChannels=[24, 96, 384, 1536], nClasses=num_classes,\n",
    "                            init_ds=2, dropout_rate=0.1, affineBN=True,\n",
    "                            in_shape=in_shape, mult=4)\n",
    "    elif model == 'LeNetZhu':\n",
    "        model = LeNetZhu(num_channels=num_channels, num_classes=num_classes)\n",
    "    else:\n",
    "        raise NotImplementedError('Model not implemented.')\n",
    "\n",
    "    print(f'Model initialized with random key {model_init_seed}.')\n",
    "    return model, model_init_seed\n",
    "\n",
    "class ResNet(torchvision.models.ResNet):\n",
    "    \"\"\"ResNet generalization for CIFAR thingies.\"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n",
    "                groups=1, base_width=64, replace_stride_with_dilation=None,\n",
    "                norm_layer=None, strides=[1, 2, 2, 2], pool='avg'):\n",
    "        \"\"\"Initialize as usual. Layers and strides are scriptable.\"\"\"\n",
    "        super(torchvision.models.ResNet, self).__init__()  # nn.Module\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 4:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                            \"or a 4-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "\n",
    "        self.inplanes = base_width\n",
    "        self.base_width = 64  # Do this to circumvent BasicBlock errors. The value is not actually used.\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        width = self.inplanes\n",
    "        for idx, layer in enumerate(layers):\n",
    "            self.layers.append(self._make_layer(block, width, layer, stride=strides[idx], dilate=replace_stride_with_dilation[idx]))\n",
    "            width *= 2\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1)) if pool == 'avg' else nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.fc = nn.Linear(width // 2 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"ConvNetBN.\"\"\"\n",
    "\n",
    "    def __init__(self, width=32, num_classes=10, num_channels=3):\n",
    "        \"\"\"Init with width and num classes.\"\"\"\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(OrderedDict([\n",
    "            ('conv0', torch.nn.Conv2d(num_channels, 1 * width, kernel_size=3, padding=1)),\n",
    "            ('bn0', torch.nn.BatchNorm2d(1 * width)),\n",
    "            ('relu0', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv1', torch.nn.Conv2d(1 * width, 2 * width, kernel_size=3, padding=1)),\n",
    "            ('bn1', torch.nn.BatchNorm2d(2 * width)),\n",
    "            ('relu1', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv2', torch.nn.Conv2d(2 * width, 2 * width, kernel_size=3, padding=1)),\n",
    "            ('bn2', torch.nn.BatchNorm2d(2 * width)),\n",
    "            ('relu2', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv3', torch.nn.Conv2d(2 * width, 4 * width, kernel_size=3, padding=1)),\n",
    "            ('bn3', torch.nn.BatchNorm2d(4 * width)),\n",
    "            ('relu3', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv4', torch.nn.Conv2d(4 * width, 4 * width, kernel_size=3, padding=1)),\n",
    "            ('bn4', torch.nn.BatchNorm2d(4 * width)),\n",
    "            ('relu4', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv5', torch.nn.Conv2d(4 * width, 4 * width, kernel_size=3, padding=1)),\n",
    "            ('bn5', torch.nn.BatchNorm2d(4 * width)),\n",
    "            ('relu5', torch.nn.ReLU()),\n",
    "\n",
    "            ('pool0', torch.nn.MaxPool2d(3)),\n",
    "\n",
    "            ('conv6', torch.nn.Conv2d(4 * width, 4 * width, kernel_size=3, padding=1)),\n",
    "            ('bn6', torch.nn.BatchNorm2d(4 * width)),\n",
    "            ('relu6', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv6', torch.nn.Conv2d(4 * width, 4 * width, kernel_size=3, padding=1)),\n",
    "            ('bn6', torch.nn.BatchNorm2d(4 * width)),\n",
    "            ('relu6', torch.nn.ReLU()),\n",
    "\n",
    "            ('conv7', torch.nn.Conv2d(4 * width, 4 * width, kernel_size=3, padding=1)),\n",
    "            ('bn7', torch.nn.BatchNorm2d(4 * width)),\n",
    "            ('relu7', torch.nn.ReLU()),\n",
    "\n",
    "            ('pool1', torch.nn.MaxPool2d(3)),\n",
    "            ('flatten', torch.nn.Flatten()),\n",
    "            ('linear', torch.nn.Linear(36 * width, num_classes))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class LeNetZhu(nn.Module):\n",
    "    \"\"\"LeNet variant from https://github.com/mit-han-lab/dlg/blob/master/models/vision.py.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10, num_channels=3):\n",
    "        \"\"\"3-Layer sigmoid Conv with large linear layer.\"\"\"\n",
    "        super().__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768, num_classes)\n",
    "        )\n",
    "        for module in self.modules():\n",
    "            self.weights_init(module)\n",
    "\n",
    "    @staticmethod\n",
    "    def weights_init(m):\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with random key 2228088985.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (23): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (24): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (25): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (26): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (27): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (28): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (29): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (30): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (31): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (32): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (33): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (34): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (35): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, _ = construct_model(arch, num_classes=10, num_channels=3)\n",
    "model.to(**setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, trainloader, validloader, defs, setup=dict(dtype=torch.float, device=torch.device('cpu'))):\n",
    "    \"\"\"Run the main interface. Train a network with specifications from the Strategy object.\"\"\"\n",
    "    stats = defaultdict(list)\n",
    "    optimizer, scheduler = set_optimizer(model, defs)\n",
    "\n",
    "    for epoch in range(defs.epochs):\n",
    "        model.train()\n",
    "        step(model, loss_fn, trainloader, optimizer, scheduler, defs, setup, stats)\n",
    "\n",
    "        if epoch % defs.validate == 0 or epoch == (defs.epochs - 1):\n",
    "            model.eval()\n",
    "            validate(model, loss_fn, validloader, defs, setup, stats)\n",
    "            # Print information about loss and accuracy\n",
    "            print_status(epoch, loss_fn, optimizer, stats)\n",
    "\n",
    "        if defs.dryrun:\n",
    "            break\n",
    "        if not (np.isfinite(stats['train_losses'][-1])):\n",
    "            print('Loss is NaN/Inf ... terminating early ...')\n",
    "            break\n",
    "\n",
    "    return stats\n",
    "\n",
    "def set_optimizer(model, defs):\n",
    "    \"\"\"Build model optimizer and scheduler from defs.\n",
    "\n",
    "    The linear scheduler drops the learning rate in intervals.\n",
    "    # Example: epochs=160 leads to drops at 60, 100, 140.\n",
    "    \"\"\"\n",
    "    if defs.optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=defs.lr, momentum=0.9,\n",
    "                                    weight_decay=defs.weight_decay, nesterov=True)\n",
    "    elif defs.optimizer == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=defs.lr, weight_decay=defs.weight_decay)\n",
    "\n",
    "    if defs.scheduler == 'linear':\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                        milestones=[120 // 2.667, 120 // 1.6,\n",
    "                                                                     120 // 1.142], gamma=0.1)\n",
    "        # Scheduler is fixed to 120 epochs so that calls with fewer epochs are equal in lr drops.\n",
    "\n",
    "    #if defs.warmup:\n",
    "    #    scheduler = GradualWarmupScheduler(optimizer, multiplier=10, total_epoch=10, after_scheduler=scheduler)\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def step(model, loss_fn, dataloader, optimizer, scheduler, defs, setup, stats):\n",
    "    \"\"\"Step through one epoch.\"\"\"\n",
    "    epoch_loss, epoch_metric = 0, 0\n",
    "    for batch, (inputs, targets) in enumerate(dataloader):\n",
    "        # Prep Mini-Batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Transfer to GPU\n",
    "        inputs = inputs.to(**setup)\n",
    "        targets = targets.to(device=setup['device'], non_blocking=NON_BLOCKING)\n",
    "\n",
    "        # Get loss\n",
    "        outputs = model(inputs)\n",
    "        loss, _, _ = loss_fn(outputs, targets)\n",
    "\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric, name, _ = loss_fn.metric(outputs, targets)\n",
    "        epoch_metric += metric.item()\n",
    "\n",
    "        if defs.scheduler == 'cyclic':\n",
    "            scheduler.step()\n",
    "        if defs.dryrun:\n",
    "            break\n",
    "    if defs.scheduler == 'linear':\n",
    "        scheduler.step()\n",
    "\n",
    "    stats['train_losses'].append(epoch_loss / (batch + 1))\n",
    "    stats['train_' + name].append(epoch_metric / (batch + 1))\n",
    "    \n",
    "def validate(model, loss_fn, dataloader, defs, setup, stats):\n",
    "    \"\"\"Validate model effectiveness of val dataset.\"\"\"\n",
    "    epoch_loss, epoch_metric = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, targets) in enumerate(dataloader):\n",
    "            # Transfer to GPU\n",
    "            inputs = inputs.to(**setup)\n",
    "            targets = targets.to(device=setup['device'], non_blocking=NON_BLOCKING)\n",
    "\n",
    "            # Get loss and metric\n",
    "            outputs = model(inputs)\n",
    "            loss, _, _ = loss_fn(outputs, targets)\n",
    "            metric, name, _ = loss_fn.metric(outputs, targets)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_metric += metric.item()\n",
    "\n",
    "            if defs.dryrun:\n",
    "                break\n",
    "\n",
    "    stats['valid_losses'].append(epoch_loss / (batch + 1))\n",
    "    stats['valid_' + name].append(epoch_metric / (batch + 1))\n",
    "    \n",
    "def print_status(epoch, loss_fn, optimizer, stats):\n",
    "    \"\"\"Print basic console printout every defs.validation epochs.\"\"\"\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    name, format = loss_fn.metric()\n",
    "    print(f'Epoch: {epoch}| lr: {current_lr:.4f} | '\n",
    "        f'Train loss is {stats[\"train_losses\"][-1]:6.4f}, Train {name}: {stats[\"train_\" + name][-1]:{format}} | '\n",
    "        f'Val loss is {stats[\"valid_losses\"][-1]:6.4f}, Val {name}: {stats[\"valid_\" + name][-1]:{format}} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-cddc2afda085>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'models/{file}'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| lr: 0.1000 | Train loss is 2.8084, Train Accuracy: 11.69% | Val loss is 2.2903, Val Accuracy: 11.06% |\n",
      "Epoch: 10| lr: 0.1000 | Train loss is 0.7832, Train Accuracy: 72.50% | Val loss is 0.7660, Val Accuracy: 73.74% |\n",
      "Epoch: 20| lr: 0.1000 | Train loss is 0.5105, Train Accuracy: 82.46% | Val loss is 0.7692, Val Accuracy: 75.00% |\n",
      "Epoch: 30| lr: 0.1000 | Train loss is 0.4318, Train Accuracy: 85.19% | Val loss is 0.6147, Val Accuracy: 79.91% |\n",
      "Epoch: 40| lr: 0.1000 | Train loss is 0.3925, Train Accuracy: 86.57% | Val loss is 0.5412, Val Accuracy: 81.61% |\n",
      "Epoch: 50| lr: 0.0100 | Train loss is 0.1112, Train Accuracy: 96.16% | Val loss is 0.2264, Val Accuracy: 92.81% |\n",
      "Epoch: 60| lr: 0.0100 | Train loss is 0.0760, Train Accuracy: 97.27% | Val loss is 0.2731, Val Accuracy: 92.24% |\n",
      "Epoch: 70| lr: 0.0100 | Train loss is 0.0690, Train Accuracy: 97.61% | Val loss is 0.2804, Val Accuracy: 92.31% |\n",
      "Epoch: 80| lr: 0.0010 | Train loss is 0.0118, Train Accuracy: 99.72% | Val loss is 0.2162, Val Accuracy: 94.08% |\n",
      "Epoch: 90| lr: 0.0010 | Train loss is 0.0067, Train Accuracy: 99.85% | Val loss is 0.2297, Val Accuracy: 94.40% |\n",
      "Epoch: 100| lr: 0.0010 | Train loss is 0.0051, Train Accuracy: 99.89% | Val loss is 0.2428, Val Accuracy: 94.45% |\n",
      "Epoch: 110| lr: 0.0001 | Train loss is 0.0037, Train Accuracy: 99.93% | Val loss is 0.2464, Val Accuracy: 94.30% |\n",
      "Epoch: 119| lr: 0.0001 | Train loss is 0.0034, Train Accuracy: 99.96% | Val loss is 0.2453, Val Accuracy: 94.31% |\n"
     ]
    }
   ],
   "source": [
    "if trained_model:\n",
    "    epochs = 120\n",
    "    file = f'{arch}_{epochs}.pth'\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(f'models/{file}'))\n",
    "    except FileNotFoundError:\n",
    "        train(model, loss_fn, trainloader, validloader, defs, setup=setup)\n",
    "        torch.save(model.state_dict(), f'models/{file}')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = torch.as_tensor(cifar10_mean, **setup)[:, None, None]\n",
    "ds = torch.as_tensor(cifar10_std, **setup)[:, None, None]\n",
    "def plot(tensor):\n",
    "    tensor = tensor.clone().detach()\n",
    "    tensor.mul_(ds).add_(dm).clamp_(0, 1)\n",
    "    if tensor.shape[0] == 1:\n",
    "        return plt.imshow(tensor[0].permute(1, 2, 0).cpu());\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, tensor.shape[0], figsize=(12, tensor.shape[0]*12))\n",
    "        for i, im in enumerate(tensor):\n",
    "            axes[i].imshow(im.permute(1, 2, 0).cpu());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_images == 1:\n",
    "    ground_truth_image = torch.as_tensor(np.array(Image.open(\"auto.jpg\").resize((32, 32), Image.BICUBIC)) / 255, \n",
    "                                         **setup)\n",
    "    ground_truth = ground_truth_image.permute(2, 0, 1).sub(dm).div(ds).unsqueeze(0).contiguous()\n",
    "    labels = torch.as_tensor((1,), device=setup['device'])\n",
    "else:\n",
    "    ground_truth, labels = [], []\n",
    "    idx = 25 # choosen randomly ... just whatever you want\n",
    "    while len(labels) < num_images:\n",
    "        img, label = validloader.dataset[idx]\n",
    "        idx += 1\n",
    "        if label not in labels:\n",
    "            labels.append(torch.as_tensor((label,), device=setup['device']))\n",
    "            ground_truth.append(img.to(**setup))\n",
    "    ground_truth = torch.stack(ground_truth)\n",
    "    labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['automobile']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(ground_truth);\n",
    "print([validloader.dataset.classes[l] for l in labels]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "\n",
    "DEFAULT_CONFIG = dict(signed=False,\n",
    "                    boxed=True,\n",
    "                    cost_fn='sim',\n",
    "                    indices='def',\n",
    "                    weights='equal',\n",
    "                    lr=0.1,\n",
    "                    optim='adam',\n",
    "                    restarts=1,\n",
    "                    max_iterations=4800,\n",
    "                    total_variation=1e-1,\n",
    "                    init='randn',\n",
    "                    filter='none',\n",
    "                    lr_decay=True,\n",
    "                    scoring_choice='loss')\n",
    "\n",
    "def _validate_config(config):\n",
    "    for key in DEFAULT_CONFIG.keys():\n",
    "        if config.get(key) is None:\n",
    "            config[key] = DEFAULT_CONFIG[key]\n",
    "    for key in config.keys():\n",
    "        if DEFAULT_CONFIG.get(key) is None:\n",
    "            raise ValueError(f'Deprecated key in config dict: {key}!')\n",
    "    return config\n",
    "\n",
    "class GradientReconstructor():\n",
    "    \"\"\"Instantiate a reconstruction algorithm.\"\"\"\n",
    "\n",
    "    def __init__(self, model, mean_std=(0.0, 1.0), config=DEFAULT_CONFIG, num_images=1):\n",
    "        \"\"\"Initialize with algorithm setup.\"\"\"\n",
    "        self.config = _validate_config(config)\n",
    "        self.model = model\n",
    "        self.setup = dict(device=next(model.parameters()).device, dtype=next(model.parameters()).dtype)\n",
    "\n",
    "        self.mean_std = mean_std\n",
    "        self.num_images = num_images\n",
    "\n",
    "        if self.config['scoring_choice'] == 'inception':\n",
    "            self.inception = InceptionScore(batch_size=1, setup=self.setup)\n",
    "\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.iDLG = True\n",
    "\n",
    "    def reconstruct(self, input_data, labels, img_shape=(3, 32, 32), dryrun=False, eval=True, tol=None):\n",
    "        \"\"\"Reconstruct image from gradient.\"\"\"\n",
    "        start_time = time.time()\n",
    "        if eval:\n",
    "            self.model.eval()\n",
    "\n",
    "        stats = defaultdict(list)\n",
    "        x = self._init_images(img_shape)\n",
    "        scores = torch.zeros(self.config['restarts'])\n",
    "\n",
    "        if labels is None:\n",
    "            if self.num_images == 1 and self.iDLG:\n",
    "                # iDLG trick:\n",
    "                last_weight_min = torch.argmin(torch.sum(input_data[-2], dim=-1), dim=-1)\n",
    "                labels = last_weight_min.detach().reshape((1,)).requires_grad_(False)\n",
    "                self.reconstruct_label = False\n",
    "            else:\n",
    "                # DLG label recovery\n",
    "                # However this also improves conditioning for some LBFGS cases\n",
    "                self.reconstruct_label = True\n",
    "\n",
    "                def loss_fn(pred, labels):\n",
    "                    labels = torch.nn.functional.softmax(labels, dim=-1)\n",
    "                    return torch.mean(torch.sum(- labels * torch.nn.functional.log_softmax(pred, dim=-1), 1))\n",
    "                self.loss_fn = loss_fn\n",
    "        else:\n",
    "            assert labels.shape[0] == self.num_images\n",
    "            self.reconstruct_label = False\n",
    "\n",
    "        try:\n",
    "            for trial in range(self.config['restarts']):\n",
    "                x_trial, labels = self._run_trial(x[trial], input_data, labels, dryrun=dryrun)\n",
    "                # Finalize\n",
    "                scores[trial] = self._score_trial(x_trial, input_data, labels)\n",
    "                x[trial] = x_trial\n",
    "                if tol is not None and scores[trial] <= tol:\n",
    "                    break\n",
    "                if dryrun:\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            print('Trial procedure manually interruped.')\n",
    "            pass\n",
    "\n",
    "        # Choose optimal result:\n",
    "        if self.config['scoring_choice'] in ['pixelmean', 'pixelmedian']:\n",
    "            x_optimal, stats = self._average_trials(x, labels, input_data, stats)\n",
    "        else:\n",
    "            print('Choosing optimal result ...')\n",
    "            scores = scores[torch.isfinite(scores)]  # guard against NaN/-Inf scores?\n",
    "            optimal_index = torch.argmin(scores)\n",
    "            print(f'Optimal result score: {scores[optimal_index]:2.4f}')\n",
    "            stats['opt'] = scores[optimal_index].item()\n",
    "            x_optimal = x[optimal_index]\n",
    "\n",
    "        print(f'Total time: {time.time()-start_time}.')\n",
    "        return x_optimal.detach(), stats\n",
    "\n",
    "    def _init_images(self, img_shape):\n",
    "        if self.config['init'] == 'randn':\n",
    "            return torch.randn((self.config['restarts'], self.num_images, *img_shape), **self.setup)\n",
    "        elif self.config['init'] == 'rand':\n",
    "            return (torch.rand((self.config['restarts'], self.num_images, *img_shape), **self.setup) - 0.5) * 2\n",
    "        elif self.config['init'] == 'zeros':\n",
    "            return torch.zeros((self.config['restarts'], self.num_images, *img_shape), **self.setup)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    def _run_trial(self, x_trial, input_data, labels, dryrun=False):\n",
    "        x_trial.requires_grad = True\n",
    "        if self.reconstruct_label:\n",
    "            output_test = self.model(x_trial)\n",
    "            labels = torch.randn(output_test.shape[1]).to(**self.setup).requires_grad_(True)\n",
    "\n",
    "            if self.config['optim'] == 'adam':\n",
    "                optimizer = torch.optim.Adam([x_trial, labels], lr=self.config['lr'])\n",
    "            elif self.config['optim'] == 'sgd':  # actually gd\n",
    "                optimizer = torch.optim.SGD([x_trial, labels], lr=0.01, momentum=0.9, nesterov=True)\n",
    "            elif self.config['optim'] == 'LBFGS':\n",
    "                optimizer = torch.optim.LBFGS([x_trial, labels])\n",
    "            else:\n",
    "                raise ValueError()\n",
    "        else:\n",
    "            if self.config['optim'] == 'adam':\n",
    "                optimizer = torch.optim.Adam([x_trial], lr=self.config['lr'])\n",
    "            elif self.config['optim'] == 'sgd':  # actually gd\n",
    "                optimizer = torch.optim.SGD([x_trial], lr=0.01, momentum=0.9, nesterov=True)\n",
    "            elif self.config['optim'] == 'LBFGS':\n",
    "                optimizer = torch.optim.LBFGS([x_trial])\n",
    "            else:\n",
    "                raise ValueError()\n",
    "\n",
    "        max_iterations = self.config['max_iterations']\n",
    "        dm, ds = self.mean_std\n",
    "        if self.config['lr_decay']:\n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                             milestones=[max_iterations // 2.667, max_iterations // 1.6,\n",
    "                                                                        max_iterations // 1.142], gamma=0.1)   # 3/8 5/8 7/8\n",
    "        try:\n",
    "            for iteration in range(max_iterations):\n",
    "                closure = self._gradient_closure(optimizer, x_trial, input_data, labels)\n",
    "                rec_loss = optimizer.step(closure)\n",
    "                if self.config['lr_decay']:\n",
    "                    scheduler.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Project into image space\n",
    "                    if self.config['boxed']:\n",
    "                        x_trial.data = torch.max(torch.min(x_trial, (1 - dm) / ds), -dm / ds)\n",
    "\n",
    "                    if (iteration + 1 == max_iterations) or iteration % 500 == 0:\n",
    "                        print(f'It: {iteration}. Rec. loss: {rec_loss.item():2.4f}.')\n",
    "\n",
    "                    if (iteration + 1) % 500 == 0:\n",
    "                        if self.config['filter'] == 'none':\n",
    "                            pass\n",
    "                        elif self.config['filter'] == 'median':\n",
    "                            x_trial.data = MedianPool2d(kernel_size=3, stride=1, padding=1, same=False)(x_trial)\n",
    "                        else:\n",
    "                            raise ValueError()\n",
    "\n",
    "                if dryrun:\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            print(f'Recovery interrupted manually in iteration {iteration}!')\n",
    "            pass\n",
    "        return x_trial.detach(), labels\n",
    "\n",
    "    def _gradient_closure(self, optimizer, x_trial, input_gradient, label):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            self.model.zero_grad()\n",
    "            loss = self.loss_fn(self.model(x_trial), label)\n",
    "            gradient = torch.autograd.grad(loss, self.model.parameters(), create_graph=True)\n",
    "            rec_loss = reconstruction_costs([gradient], input_gradient,\n",
    "                                            cost_fn=self.config['cost_fn'], indices=self.config['indices'],\n",
    "                                            weights=self.config['weights'])\n",
    "\n",
    "            if self.config['total_variation'] > 0:\n",
    "                rec_loss += self.config['total_variation'] * TV(x_trial)\n",
    "            rec_loss.backward()\n",
    "            if self.config['signed']:\n",
    "                x_trial.grad.sign_()\n",
    "            return rec_loss\n",
    "        return closure\n",
    "\n",
    "    def _score_trial(self, x_trial, input_gradient, label):\n",
    "        if self.config['scoring_choice'] == 'loss':\n",
    "            self.model.zero_grad()\n",
    "            x_trial.grad = None\n",
    "            loss = self.loss_fn(self.model(x_trial), label)\n",
    "            gradient = torch.autograd.grad(loss, self.model.parameters(), create_graph=False)\n",
    "            return reconstruction_costs([gradient], input_gradient,\n",
    "                                        cost_fn=self.config['cost_fn'], indices=self.config['indices'],\n",
    "                                        weights=self.config['weights'])\n",
    "        elif self.config['scoring_choice'] == 'tv':\n",
    "            return TV(x_trial)\n",
    "        elif self.config['scoring_choice'] == 'inception':\n",
    "            # We do not care about diversity here!\n",
    "            return self.inception(x_trial)\n",
    "        elif self.config['scoring_choice'] in ['pixelmean', 'pixelmedian']:\n",
    "            return 0.0\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    def _average_trials(self, x, labels, input_data, stats):\n",
    "        print(f'Computing a combined result via {self.config[\"scoring_choice\"]} ...')\n",
    "        if self.config['scoring_choice'] == 'pixelmedian':\n",
    "            x_optimal, _ = x.median(dim=0, keepdims=False)\n",
    "        elif self.config['scoring_choice'] == 'pixelmean':\n",
    "            x_optimal = x.mean(dim=0, keepdims=False)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        if self.reconstruct_label:\n",
    "            labels = self.model(x_optimal).softmax(dim=1)\n",
    "        loss = self.loss_fn(self.model(x_optimal), labels)\n",
    "        gradient = torch.autograd.grad(loss, self.model.parameters(), create_graph=False)\n",
    "        stats['opt'] = reconstruction_costs([gradient], input_data,\n",
    "                                            cost_fn=self.config['cost_fn'],\n",
    "                                            indices=self.config['indices'],\n",
    "                                            weights=self.config['weights'])\n",
    "        print(f'Optimal result score: {stats[\"opt\"]:2.4f}')\n",
    "        return x_optimal, stats\n",
    "\n",
    "class InceptionScore(torch.nn.Module):\n",
    "    \"\"\"Class that manages and returns the inception score of images.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=32, setup=dict(device=torch.device('cpu'), dtype=torch.float)):\n",
    "        \"\"\"Initialize with setup and target inception batch size.\"\"\"\n",
    "        super().__init__()\n",
    "        self.preprocessing = torch.nn.Upsample(size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        self.model = torchvision.models.inception_v3(pretrained=True).to(**setup)\n",
    "        self.model.eval()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, image_batch):\n",
    "        \"\"\"Image batch should have dimensions BCHW and should be normalized.\n",
    "\n",
    "        B should be divisible by self.batch_size.\n",
    "        \"\"\"\n",
    "        B, C, H, W = image_batch.shape\n",
    "        batches = B // self.batch_size\n",
    "        scores = []\n",
    "        for batch in range(batches):\n",
    "            input = self.preprocessing(image_batch[batch * self.batch_size: (batch + 1) * self.batch_size])\n",
    "            scores.append(self.model(input))\n",
    "        prob_yx = torch.nn.functional.softmax(torch.cat(scores, 0), dim=1)\n",
    "        entropy = torch.where(prob_yx > 0, -prob_yx * prob_yx.log(), torch.zeros_like(prob_yx))\n",
    "        return entropy.sum()\n",
    "\n",
    "def reconstruction_costs(gradients, input_gradient, cost_fn='l2', indices='def', weights='equal'):\n",
    "    \"\"\"Input gradient is given data.\"\"\"\n",
    "    if isinstance(indices, list):\n",
    "        pass\n",
    "    elif indices == 'def':\n",
    "        indices = torch.arange(len(input_gradient))\n",
    "    elif indices == 'batch':\n",
    "        indices = torch.randperm(len(input_gradient))[:8]\n",
    "    elif indices == 'topk-1':\n",
    "        _, indices = torch.topk(torch.stack([p.norm() for p in input_gradient], dim=0), 4)\n",
    "    elif indices == 'top10':\n",
    "        _, indices = torch.topk(torch.stack([p.norm() for p in input_gradient], dim=0), 10)\n",
    "    elif indices == 'top50':\n",
    "        _, indices = torch.topk(torch.stack([p.norm() for p in input_gradient], dim=0), 50)\n",
    "    elif indices in ['first', 'first4']:\n",
    "        indices = torch.arange(0, 4)\n",
    "    elif indices == 'first5':\n",
    "        indices = torch.arange(0, 5)\n",
    "    elif indices == 'first10':\n",
    "        indices = torch.arange(0, 10)\n",
    "    elif indices == 'first50':\n",
    "        indices = torch.arange(0, 50)\n",
    "    elif indices == 'last5':\n",
    "        indices = torch.arange(len(input_gradient))[-5:]\n",
    "    elif indices == 'last10':\n",
    "        indices = torch.arange(len(input_gradient))[-10:]\n",
    "    elif indices == 'last50':\n",
    "        indices = torch.arange(len(input_gradient))[-50:]\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    ex = input_gradient[0]\n",
    "    if weights == 'linear':\n",
    "        weights = torch.arange(len(input_gradient), 0, -1, dtype=ex.dtype, device=ex.device) / len(input_gradient)\n",
    "    elif weights == 'exp':\n",
    "        weights = torch.arange(len(input_gradient), 0, -1, dtype=ex.dtype, device=ex.device)\n",
    "        weights = weights.softmax(dim=0)\n",
    "        weights = weights / weights[0]\n",
    "    else:\n",
    "        weights = input_gradient[0].new_ones(len(input_gradient))\n",
    "\n",
    "    total_costs = 0\n",
    "    for trial_gradient in gradients:\n",
    "        pnorm = [0, 0]\n",
    "        costs = 0\n",
    "        if indices == 'topk-2':\n",
    "            _, indices = torch.topk(torch.stack([p.norm().detach() for p in trial_gradient], dim=0), 4)\n",
    "        for i in indices:\n",
    "            if cost_fn == 'l2':\n",
    "                costs += ((trial_gradient[i] - input_gradient[i]).pow(2)).sum() * weights[i]\n",
    "            elif cost_fn == 'l1':\n",
    "                costs += ((trial_gradient[i] - input_gradient[i]).abs()).sum() * weights[i]\n",
    "            elif cost_fn == 'max':\n",
    "                costs += ((trial_gradient[i] - input_gradient[i]).abs()).max() * weights[i]\n",
    "            elif cost_fn == 'sim':\n",
    "                costs -= (trial_gradient[i] * input_gradient[i]).sum() * weights[i]\n",
    "                pnorm[0] += trial_gradient[i].pow(2).sum() * weights[i]\n",
    "                pnorm[1] += input_gradient[i].pow(2).sum() * weights[i]\n",
    "            elif cost_fn == 'simlocal':\n",
    "                costs += 1 - torch.nn.functional.cosine_similarity(trial_gradient[i].flatten(),\n",
    "                                                                input_gradient[i].flatten(),\n",
    "                                                                   0, 1e-10) * weights[i]\n",
    "        if cost_fn == 'sim':\n",
    "            costs = 1 + costs / pnorm[0].sqrt() / pnorm[1].sqrt()\n",
    "\n",
    "        # Accumulate final costs\n",
    "        total_costs += costs\n",
    "    return total_costs / len(gradients)\n",
    "\n",
    "class MedianPool2d(nn.Module):\n",
    "    \"\"\"Median pool (usable as median filter when stride=1) module.\n",
    "\n",
    "    Args:\n",
    "        kernel_size: size of pooling kernel, int or 2-tuple\n",
    "        stride: pool stride, int or 2-tuple\n",
    "        padding: pool padding, int or 4-tuple (l, r, t, b) as in pytorch F.pad\n",
    "        same: override padding and enforce same padding, boolean\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size=3, stride=1, padding=0, same=True):\n",
    "        \"\"\"Initialize with kernel_size, stride, padding.\"\"\"\n",
    "        super().__init__()\n",
    "        self.k = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _quadruple(padding)  # convert to l, r, t, b\n",
    "        self.same = same\n",
    "\n",
    "    def _padding(self, x):\n",
    "        if self.same:\n",
    "            ih, iw = x.size()[2:]\n",
    "            if ih % self.stride[0] == 0:\n",
    "                ph = max(self.k[0] - self.stride[0], 0)\n",
    "            else:\n",
    "                ph = max(self.k[0] - (ih % self.stride[0]), 0)\n",
    "            if iw % self.stride[1] == 0:\n",
    "                pw = max(self.k[1] - self.stride[1], 0)\n",
    "            else:\n",
    "                pw = max(self.k[1] - (iw % self.stride[1]), 0)\n",
    "            pl = pw // 2\n",
    "            pr = pw - pl\n",
    "            pt = ph // 2\n",
    "            pb = ph - pt\n",
    "            padding = (pl, pr, pt, pb)\n",
    "        else:\n",
    "            padding = self.padding\n",
    "        return padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        # using existing pytorch functions and tensor ops so that we get autograd,\n",
    "        # would likely be more efficient to implement from scratch at C/Cuda level\n",
    "        x = F.pad(x, self._padding(x), mode='reflect')\n",
    "        x = x.unfold(2, self.k[0], self.stride[0]).unfold(3, self.k[1], self.stride[1])\n",
    "        x = x.contiguous().view(x.size()[:4] + (-1,)).median(dim=-1)[0]\n",
    "        return x\n",
    "\n",
    "def TV(x):\n",
    "    \"\"\"Anisotropic TV.\"\"\"\n",
    "    dx = torch.mean(torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]))\n",
    "    dy = torch.mean(torch.abs(x[:, :, :-1, :] - x[:, :, 1:, :]))\n",
    "    return dx + dy\n",
    "\n",
    "def psnr(img_batch, ref_batch, batched=False, factor=1.0):\n",
    "    \"\"\"Standard PSNR.\"\"\"\n",
    "    def get_psnr(img_in, img_ref):\n",
    "        mse = ((img_in - img_ref)**2).mean()\n",
    "        if mse > 0 and torch.isfinite(mse):\n",
    "            return (10 * torch.log10(factor**2 / mse))\n",
    "        elif not torch.isfinite(mse):\n",
    "            return img_batch.new_tensor(float('nan'))\n",
    "        else:\n",
    "            return img_batch.new_tensor(float('inf'))\n",
    "\n",
    "    if batched:\n",
    "        psnr = get_psnr(img_batch.detach(), ref_batch)\n",
    "    else:\n",
    "        [B, C, m, n] = img_batch.shape\n",
    "        psnrs = []\n",
    "        for sample in range(B):\n",
    "            psnrs.append(get_psnr(img_batch.detach()[sample, :, :, :], ref_batch[sample, :, :, :]))\n",
    "        psnr = torch.stack(psnrs, dim=0).mean()\n",
    "\n",
    "    return psnr.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0. Rec. loss: 0.9697.\n",
      "It: 500. Rec. loss: 0.1367.\n",
      "It: 1000. Rec. loss: 0.1356.\n",
      "It: 1500. Rec. loss: 0.1090.\n",
      "It: 2000. Rec. loss: 0.0864.\n",
      "It: 2500. Rec. loss: 0.0853.\n",
      "It: 3000. Rec. loss: 0.0826.\n",
      "It: 3500. Rec. loss: 0.0816.\n",
      "It: 3999. Rec. loss: 0.0808.\n",
      "Choosing optimal result ...\n",
      "Optimal result score: 0.0807\n",
      "Total time: 291.80804538726807.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "target_loss, _, _ = loss_fn(model(ground_truth), labels)\n",
    "input_gradient = torch.autograd.grad(target_loss, model.parameters())\n",
    "input_gradient = [grad.detach() for grad in input_gradient]\n",
    "\n",
    "config = dict(signed=True,\n",
    "        boxed=True,\n",
    "        cost_fn='sim',\n",
    "        indices='def',\n",
    "        weights='equal',\n",
    "        lr=0.1,\n",
    "        optim='adam',\n",
    "        restarts=1,\n",
    "        max_iterations=4000,\n",
    "        total_variation=1e-6,\n",
    "        init='randn',\n",
    "        filter='none',\n",
    "        lr_decay=True,\n",
    "        scoring_choice='loss')\n",
    "\n",
    "rec_machine = GradientReconstructor(model, (dm, ds), config, num_images=num_images)\n",
    "output, stats = rec_machine.reconstruct(input_gradient, labels, img_shape=(3, 32, 32))\n",
    "\n",
    "test_mse = (output.detach() - ground_truth).pow(2).mean()\n",
    "feat_mse = (model(output.detach())- model(ground_truth)).pow(2).mean()  \n",
    "test_psnr = psnr(output, ground_truth, factor=1/ds)\n",
    "\n",
    "plot(output)\n",
    "plt.title(f\"Rec. loss: {stats['opt']:2.4f} | MSE: {test_mse:2.4f} \"\n",
    "        f\"| PSNR: {test_psnr:4.2f} | FMSE: {feat_mse:2.4e} |\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
