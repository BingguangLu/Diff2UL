{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bingguang/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/bingguang/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "<ipython-input-1-5f0c4c32e506>:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  benign_model.load_state_dict(torch.load(benign_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected images saved in folder: ./image\n",
      "Fine-tuning Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "num_data_points = 1\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = torch.nn.Linear(64 * 14 * 14, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "benign_model_path = './model/benign_model.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "benign_model = SimpleCNN().to(device)\n",
    "benign_model.load_state_dict(torch.load(benign_model_path, map_location=device))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=len(mnist_dataset), shuffle=False)\n",
    "\n",
    "all_data = next(iter(mnist_loader))\n",
    "mnist_X, mnist_y = all_data[0].to(device), all_data[1].to(device)\n",
    "\n",
    "selected_indices = torch.randperm(len(mnist_X))[:num_data_points]\n",
    "selected_X = mnist_X[selected_indices]\n",
    "selected_y = mnist_y[selected_indices]\n",
    "\n",
    "image_folder = './image'\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "for i, img_tensor in enumerate(selected_X):\n",
    "    img = to_pil_image((img_tensor * 0.5 + 0.5).cpu())\n",
    "    img.save(os.path.join(image_folder, f\"selected_image_{i}.png\"))\n",
    "print(f\"Selected images saved in folder: {image_folder}\")\n",
    "\n",
    "target_model = SimpleCNN().to(device)\n",
    "target_model.load_state_dict(benign_model.state_dict())\n",
    "target_model.train()\n",
    "\n",
    "target_optimizer = torch.optim.SGD(target_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1): \n",
    "    running_loss = 0.0\n",
    "    for i in range(len(selected_indices)):\n",
    "        images = selected_X[i:i+1]\n",
    "        labels = selected_y[i:i+1]\n",
    "\n",
    "        target_optimizer.zero_grad()\n",
    "        outputs = target_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        target_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Fine-tuning Loss: {running_loss / len(selected_indices):.4f}\")\n",
    "\n",
    "torch.save(target_model.state_dict(), './model/target_model_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-24f087230357>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  target_model.load_state_dict(torch.load('./model/target_model.pth', map_location='cuda'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-24f087230357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparam_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;31m# no line search, simply move with fixed-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# re-evaluate function only if not in last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/iv/lib/python3.8/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_add_grad\u001b[0;34m(self, step_size, update)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mnumel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# view as to avoid deprecated pointwise semantics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "\n",
    "X = torch.randn(num_data_points, 1, 28, 28, requires_grad=True, device=device)\n",
    "y = torch.randint(0, 10, (num_data_points,), device=device, dtype=torch.long)\n",
    "\n",
    "#benign_model = SimpleCNN().to('cuda')\n",
    "#benign_model.load_state_dict(torch.load('./model/benign_model.pth', map_location='cuda'))\n",
    "\n",
    "target_model = SimpleCNN().to('cuda')\n",
    "target_model.load_state_dict(torch.load('./model/target_model.pth', map_location='cuda'))\n",
    "target_params = {name: param.detach() for name, param in target_model.named_parameters()}\n",
    "\n",
    "optimizer = torch.optim.LBFGS([X, y], lr=0.1, max_iter=20)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        fine_tuned_model = SimpleCNN().to('cuda')\n",
    "        fine_tuned_model.load_state_dict(benign_model.state_dict())\n",
    "        fine_tuned_model.train()\n",
    "\n",
    "        fine_tune_optimizer = torch.optim.SGD(fine_tuned_model.parameters(), lr=0.01)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            images = X[i:i + 1]\n",
    "            labels = y[i:i + 1].long()\n",
    "\n",
    "            fine_tune_optimizer.zero_grad()\n",
    "            outputs = fine_tuned_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            fine_tune_optimizer.step()\n",
    "\n",
    "        param_diff = sum(\n",
    "            torch.norm(param - target_params[name])**2\n",
    "            for name, param in fine_tuned_model.named_parameters()\n",
    "        )\n",
    "\n",
    "        param_diff.backward()\n",
    "        return param_diff\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        final_loss = closure()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Total Loss: {final_loss.item():.4f}\")\n",
    "\n",
    "optimized_X = X.detach()\n",
    "optimized_y = y.detach()\n",
    "torch.save({'X': optimized_X, 'y': optimized_y}, 'optimized_X_y.pth')\n",
    "print(\"Optimized training set saved as 'optimized_X_y.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-882d304bade9>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimized_X = torch.load(optimized_X_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying images from ./image folder:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "optimized_X_path = 'optimized_X.pth'\n",
    "optimized_X = torch.load(optimized_X_path)\n",
    "\n",
    "num_to_display = num_data_points \n",
    "for i in range(num_to_display):\n",
    "    plt.imshow(optimized_X[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title(f\"Optimized X - Image {i}\")\n",
    "    plt.show()\n",
    "\n",
    "image_folder = './image'\n",
    "image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.png')])\n",
    "\n",
    "print(\"Displaying images from ./image folder:\")\n",
    "for image_file in image_files[:num_to_display]:\n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    img = Image.open(img_path)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Image: {image_file}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Epoch 1/10, Total Loss: 12.3218\n",
      "Optimized training set X saved as 'optimized_X.pth'\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(num_data_points, 1, 28, 28, requires_grad=True, device=device)\n",
    "y = torch.randint(0, 10, (num_data_points,), device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam([X], lr=0.01)\n",
    "\n",
    "target_params = {name: param.detach() for name, param in target_model.named_parameters()}\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    idx = epoch % num_data_points\n",
    "    \n",
    "    fine_tuned_model = SimpleCNN().to(device)\n",
    "    fine_tuned_model.load_state_dict(benign_model.state_dict())\n",
    "    fine_tuned_model.train()\n",
    "\n",
    "    fine_tune_optimizer = torch.optim.SGD(fine_tuned_model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1):\n",
    "        running_loss = 0.0\n",
    "        for i in range(len(selected_indices)):\n",
    "            images = X[idx:idx + 1]\n",
    "            labels = y[idx:idx + 1]\n",
    "\n",
    "            fine_tune_optimizer.zero_grad()\n",
    "            outputs = fine_tuned_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            fine_tune_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "    param_diff = sum(\n",
    "        torch.norm(param - target_params[name])**2\n",
    "        for name, param in fine_tuned_model.named_parameters()\n",
    "    )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    param_diff.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Total Loss: {param_diff.item():.4f}\")\n",
    "\n",
    "optimized_X = X.detach()\n",
    "torch.save(optimized_X, 'optimized_X.pth')\n",
    "print(\"Optimized training set X saved as 'optimized_X.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
